{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oF6slvDW1ceG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgX9Bso9_9VV"
      },
      "outputs": [],
      "source": [
        "!pip install xlsxwriter tqdm\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import xlsxwriter\n",
        "import cv2\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMrIKXACAB45"
      },
      "outputs": [],
      "source": [
        "# ----------------------- CONFIG ------------------------\n",
        "batch_size = 16\n",
        "epochs = 25\n",
        "data_augmentation = True\n",
        "num_classes = 4\n",
        "IMG_SIZE = (224, 224)\n",
        "input_shape = (224, 224, 3)\n",
        "subtract_pixel_mean = True\n",
        "version = 2\n",
        "n = 3\n",
        "\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "model_type = 'ResNet%dv%d' % (depth, version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XA6jCOeVAFye"
      },
      "outputs": [],
      "source": [
        "# ⚠️ Update these with your own dataset paths:\n",
        "Train_DIR = \"/content/drive/MyDrive/new_split/train\"\n",
        "Test_DIR = \"/content/drive/MyDrive/new_split/test\"\n",
        "result_excel_link = \"/content/drive/MyDrive/ECG_CLASSIFICATION_RESNET/RESNET_11/RESNET11_RESULTS/ResNet_epoch25.xlsx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmPKMWWbAbzh"
      },
      "outputs": [],
      "source": [
        "# Classes based on your dataset\n",
        "classes = ['Normal Heartbeat', 'Abnormal Heartbeat', 'Myocardial Infarction (MI)', 'History of MI']\n",
        "class_map = {label: i for i, label in enumerate(classes)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBjbMJ-pAfyy"
      },
      "outputs": [],
      "source": [
        "start1= time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gjb8Bsb-ISRR"
      },
      "outputs": [],
      "source": [
        "# Function to load data from folder structure with loading feedback\n",
        "def load_data_from_directory(base_dir, classes, class_map, IMG_SIZE):\n",
        "    data = []\n",
        "    total_images = sum(len(os.listdir(os.path.join(base_dir, label))) for label in classes)\n",
        "\n",
        "    print(f\"Loading {total_images} images from '{base_dir}'...\")\n",
        "\n",
        "    # Use tqdm to create a progress bar\n",
        "    with tqdm(total=total_images, unit=\"image\") as pbar:\n",
        "        for label in classes:\n",
        "            path = os.path.join(base_dir, label)\n",
        "            for img_name in os.listdir(path):\n",
        "                try:\n",
        "                    img_path = os.path.join(path, img_name)\n",
        "                    img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # Load as RGB\n",
        "\n",
        "                    # Check if image is successfully loaded\n",
        "                    if img is None:\n",
        "                        raise ValueError(f\"Image {img_name} could not be read.\")\n",
        "\n",
        "                    # Resize to (width, height) = (250, 200) to match model input (200, 250, 3)\n",
        "                    img = cv2.resize(img, (IMG_SIZE[1], IMG_SIZE[0]), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "                    # Normalize pixel values to [0, 1]\n",
        "                    img = img.astype('float32') / 255.0\n",
        "\n",
        "                    # Append image, label, and name to data\n",
        "                    data.append([np.array(img), class_map[label], img_name])\n",
        "\n",
        "                    # Update progress bar\n",
        "                    pbar.update(1)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {img_name}: {e}\")\n",
        "                    pbar.update(1)  # Still update progress even if there's an error\n",
        "\n",
        "    shuffle(data)\n",
        "    print(\"Loading complete!\")\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMDYYE6kAlxK"
      },
      "outputs": [],
      "source": [
        "train_data = load_data_from_directory(Train_DIR, classes, class_map, IMG_SIZE)\n",
        "test_data = load_data_from_directory(Test_DIR, classes, class_map, IMG_SIZE)\n",
        "\n",
        "trainImages = np.array([i[0] for i in train_data])\n",
        "trainLabels = to_categorical([i[1] for i in train_data], num_classes)\n",
        "\n",
        "testImages = np.array([i[0] for i in test_data])\n",
        "testLabels = to_categorical([i[1] for i in test_data], num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onIGvMcnAq_W"
      },
      "outputs": [],
      "source": [
        "# ------------------- MODEL BUILDING ---------------------\n",
        "def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 20:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 15:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 10:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 5:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate:', lr)\n",
        "    return lr\n",
        "\n",
        "def resnet_layer(inputs, num_filters=16, kernel_size=3, strides=1,\n",
        "                 activation='relu', batch_normalization=True, conv_first=True):\n",
        "    conv = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same',\n",
        "                  kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes):\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2')\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs, num_filters=num_filters_in)\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            num_filters_out = num_filters_in * (4 if stage == 0 else 2)\n",
        "            if res_block == 0 and stage != 0:\n",
        "                strides = 2\n",
        "            y = resnet_layer(x, num_filters_in, strides=strides)\n",
        "            y = resnet_layer(y, num_filters_out, activation=None)\n",
        "            if res_block == 0:\n",
        "                x = resnet_layer(x, num_filters_out, kernel_size=1, strides=strides, activation=None, batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters_in = num_filters_out\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax', kernel_initializer='he_normal')(y)\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "model = resnet_v2(input_shape=input_shape, depth=depth, num_classes=num_classes)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciE715T7Asmb"
      },
      "outputs": [],
      "source": [
        "# --------------------- TRAIN ----------------------\n",
        "start_time = time.time()\n",
        "callbacks = [\n",
        "    ModelCheckpoint(filepath=f'{model_type}_best.h5', monitor='val_accuracy', save_best_only=True),\n",
        "    ReduceLROnPlateau(factor=np.sqrt(0.1), patience=5, min_lr=0.5e-6),\n",
        "    LearningRateScheduler(lr_schedule)\n",
        "]\n",
        "\n",
        "if not data_augmentation:\n",
        "    history = model.fit(trainImages, trainLabels,\n",
        "                        batch_size=batch_size, epochs=epochs,\n",
        "                        validation_data=(testImages, testLabels),\n",
        "                        shuffle=True, callbacks=callbacks)\n",
        "else:\n",
        "    datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "    datagen.fit(trainImages)\n",
        "    history = model.fit(datagen.flow(trainImages, trainLabels, batch_size=batch_size),\n",
        "                        validation_data=(testImages, testLabels),\n",
        "                        epochs=epochs, verbose=1, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMqtErBKAyP5"
      },
      "outputs": [],
      "source": [
        "# --------------------- EVALUATE ----------------------\n",
        "scores = model.evaluate(testImages, testLabels, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-usWmfUZGIy6"
      },
      "outputs": [],
      "source": [
        "# Block 9: Evaluate the Model and Generate Metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load the best saved model\n",
        "try:\n",
        "    best_model = load_model(f'{model_type}_best.h5')\n",
        "    print(f\"Loaded best model from {model_type}_best.h5\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading best model: {e}. Using the current model instead.\")\n",
        "    best_model = model  # Fallback to the trained model if checkpoint loading fails\n",
        "\n",
        "# Evaluate the model on test data\n",
        "scores = best_model.evaluate(testImages, testLabels, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "\n",
        "# Predict on test data\n",
        "preds = best_model.predict(testImages)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "pred_labels = np.argmax(preds, axis=1)\n",
        "\n",
        "# Convert one-hot encoded testLabels to class indices\n",
        "true_labels = np.argmax(testLabels, axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "class_names = classes  # Use the defined classes ['N', 'L', 'R', 'A', 'V']\n",
        "report = classification_report(true_labels, pred_labels, target_names=class_names)\n",
        "print(\"Classification Report:\\n\")\n",
        "print(report)\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Save results to Excel\n",
        "try:\n",
        "    workbook = xlsxwriter.Workbook(result_excel_link)\n",
        "    worksheet = workbook.add_worksheet()\n",
        "    # Write headers\n",
        "    worksheet.write(0, 0, \"Filename\")\n",
        "    worksheet.write(0, 1, \"Original Label\")\n",
        "    worksheet.write(0, 2, \"Predicted Label\")\n",
        "    worksheet.write(0, 3, \"Match (1/0)\")\n",
        "    worksheet.write(0, 4, \"Total Execution Time\")\n",
        "\n",
        "    # Write data\n",
        "    test_img_num = len(testImages)\n",
        "    for i, (img_arr, true_label_numeric, filename) in enumerate(test_data[:test_img_num]):\n",
        "        pred_label_numeric = np.argmax(preds[i])\n",
        "        true_label = classes[true_label_numeric]\n",
        "        pred_label = classes[pred_label_numeric]\n",
        "        match = 1 if true_label == pred_label else 0\n",
        "        worksheet.write(i +1, 0, filename)\n",
        "        worksheet.write(i + 1, 1, true_label)\n",
        "        worksheet.write(i + 1, 2, pred_label)\n",
        "        worksheet.write(i + 1, 3, match)\n",
        "\n",
        "    # Write total execution time\n",
        "    end1 = time.time()\n",
        "    time_taken = end1 - start1\n",
        "    worksheet.write(1, 4, time_taken)\n",
        "\n",
        "    # Close the workbook\n",
        "    workbook.close()\n",
        "    print(f\"Results successfully written to {result_excel_link}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while writing to Excel: {e}\")\n",
        "\n",
        "# Plot training results\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assume 'history' is the object returned by model.fit()\n",
        "# Example:\n",
        "# history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
        "\n",
        "# Plot Training & Validation Accuracy\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Training & Validation Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ysrFh0Bt-72E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMrsARJJA1rK"
      },
      "outputs": [],
      "source": [
        "# --------------------- RESULTS TO EXCEL ----------------------\n",
        "preds = model.predict(testImages)\n",
        "predicted_labels_numeric = np.argmax(preds, axis=1)\n",
        "true_labels_numeric = np.argmax(testLabels, axis=1)\n",
        "predicted_labels = [classes[i] for i in predicted_labels_numeric]\n",
        "true_labels = [classes[i] for i in true_labels_numeric]\n",
        "\n",
        "workbook = xlsxwriter.Workbook(result_excel_link)\n",
        "worksheet = workbook.add_worksheet()\n",
        "worksheet.write(0, 0, 'True Label')\n",
        "worksheet.write(0, 1, 'Predicted Label')\n",
        "worksheet.write(0, 2, 'Match (1/0)')\n",
        "worksheet.write(0, 3, 'Total Execution Time')\n",
        "\n",
        "for i in range(len(testImages)):\n",
        "    match = 1 if predicted_labels[i] == true_labels[i] else 0\n",
        "    worksheet.write(i + 1, 0, true_labels[i])\n",
        "    worksheet.write(i + 1, 1, predicted_labels[i])\n",
        "    worksheet.write(i + 1, 2, match)\n",
        "\n",
        "worksheet.write(1, 3, time.time() - start_time)\n",
        "workbook.close()\n",
        "\n",
        "print(f\"✅ Results saved to {result_excel_link}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('final_resnet20_ecg_epoch75_model.h5')  # HDF5 format\n"
      ],
      "metadata": {
        "id": "xqXTPMLv_zZA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}